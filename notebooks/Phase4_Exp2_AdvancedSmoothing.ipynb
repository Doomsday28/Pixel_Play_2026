{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nfrom scipy.ndimage import gaussian_filter1d, median_filter\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {DEVICE}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:11:59.883594Z","iopub.execute_input":"2026-01-07T06:11:59.883810Z","iopub.status.idle":"2026-01-07T06:12:05.469686Z","shell.execute_reply.started":"2026-01-07T06:11:59.883787Z","shell.execute_reply":"2026-01-07T06:12:05.469084Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Paths\nBASE_PATH = \"/kaggle/input/pixel-play-26\"\nDATA_ROOT = os.path.join(BASE_PATH, os.listdir(BASE_PATH)[0])\nAVENUE_PATH = os.path.join(DATA_ROOT, \"Avenue_Corrupted\", \"Dataset\")\nTRAIN_VIDEOS = os.path.join(AVENUE_PATH, \"training_videos\")\nTEST_VIDEOS = os.path.join(AVENUE_PATH, \"testing_videos\")\nOUTPUT_DIR = \"/kaggle/working\"\n\nCONFIG = {\n    'image_size': (128, 128),\n    'latent_dim': 128,\n    'batch_size': 64,\n    'num_epochs': 25,\n    'learning_rate': 2e-4,\n    'patience': 5,\n    'seeds': [42, 123, 456, 789],\n}\nprint(\"Config ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:14:14.208334Z","iopub.execute_input":"2026-01-07T06:14:14.209007Z","iopub.status.idle":"2026-01-07T06:14:14.215589Z","shell.execute_reply.started":"2026-01-07T06:14:14.208981Z","shell.execute_reply":"2026-01-07T06:14:14.214798Z"}},"outputs":[{"name":"stdout","text":"Config ready\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def discover_frames(video_dir):\n    frames = defaultdict(list)\n    if not os.path.exists(video_dir):\n        return frames\n    for vf in sorted(glob.glob(os.path.join(video_dir, '*'))):\n        if not os.path.isdir(vf):\n            continue\n        try:\n            vid = int(os.path.basename(vf))\n        except:\n            continue\n        for ff in sorted(glob.glob(os.path.join(vf, '*.jpg'))):\n            fname = os.path.splitext(os.path.basename(ff))[0]\n            if fname.startswith('frame_'):\n                fname = fname.replace('frame_', '')\n            try:\n                fnum = int(fname)\n                frames[vid].append((fnum, ff))\n            except:\n                continue\n        frames[vid].sort(key=lambda x: x[0])\n    return dict(frames)\n\ntrain_frames = discover_frames(TRAIN_VIDEOS)\ntest_frames = discover_frames(TEST_VIDEOS)\nprint(f\"Train: {sum(len(v) for v in train_frames.values())} frames\")\nprint(f\"Test: {sum(len(v) for v in test_frames.values())} frames\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:14:24.172838Z","iopub.execute_input":"2026-01-07T06:14:24.173202Z","iopub.status.idle":"2026-01-07T06:14:24.719358Z","shell.execute_reply.started":"2026-01-07T06:14:24.173179Z","shell.execute_reply":"2026-01-07T06:14:24.718586Z"}},"outputs":[{"name":"stdout","text":"Train: 9204 frames\nTest: 11706 frames\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"test_frame_ids = []\ntest_frame_info = []\nfor vid in sorted(test_frames.keys()):\n    for fnum, _ in test_frames[vid]:\n        test_frame_ids.append(f\"{vid}_{fnum}\")\n        test_frame_info.append((vid, fnum))\n\ntest_video_fnums = defaultdict(list)\nfor vid, fnum in test_frame_info:\n    test_video_fnums[vid].append(fnum)\nfor vid in test_video_fnums:\n    test_video_fnums[vid] = sorted(set(test_video_fnums[vid]))\n\nprint(f\"Test IDs: {len(test_frame_ids)}\")\nprint(f\"Test videos: {len(test_video_fnums)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:14:34.626653Z","iopub.execute_input":"2026-01-07T06:14:34.627362Z","iopub.status.idle":"2026-01-07T06:14:34.641875Z","shell.execute_reply.started":"2026-01-07T06:14:34.627336Z","shell.execute_reply":"2026-01-07T06:14:34.641328Z"}},"outputs":[{"name":"stdout","text":"Test IDs: 11706\nTest videos: 21\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def load_to_gpu(frames_dict, image_size, device):\n    total = sum(len(v) for v in frames_dict.values())\n    H, W = image_size\n    tensors = torch.zeros(total, 3, H, W, dtype=torch.float32, device=device)\n    info = []\n    idx = 0\n    pbar = tqdm(total=total, desc=\"Loading\")\n    for vid in sorted(frames_dict.keys()):\n        for fnum, path in frames_dict[vid]:\n            img = Image.open(path).convert('RGB').resize((W, H), Image.BILINEAR)\n            arr = np.array(img, dtype=np.float32) / 127.5 - 1.0\n            tensors[idx] = torch.from_numpy(arr).permute(2, 0, 1)\n            info.append((vid, fnum))\n            idx += 1\n            pbar.update(1)\n    pbar.close()\n    return tensors, info\n\nprint(\"Loading data...\")\ntrain_tensors, train_info = load_to_gpu(train_frames, CONFIG['image_size'], DEVICE)\ntest_tensors, test_info = load_to_gpu(test_frames, CONFIG['image_size'], DEVICE)\nprint(f\"GPU: {torch.cuda.memory_allocated()/1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:14:44.051400Z","iopub.execute_input":"2026-01-07T06:14:44.051951Z","iopub.status.idle":"2026-01-07T06:18:17.279913Z","shell.execute_reply.started":"2026-01-07T06:14:44.051928Z","shell.execute_reply":"2026-01-07T06:18:17.279148Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading:   0%|          | 0/9204 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b6bfb23c765438eb0824ef95ee0b996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading:   0%|          | 0/11706 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4079337d8bb748e28fc4b9841e74a68b"}},"metadata":{}},{"name":"stdout","text":"GPU: 4.11 GB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"class SimpleAE(nn.Module):\n    def __init__(self, latent_dim=128):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(32, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, True),\n        )\n        self.fc_enc = nn.Sequential(nn.Flatten(), nn.Linear(512*4*4, latent_dim))\n        self.fc_dec = nn.Sequential(nn.Linear(latent_dim, 512*4*4), nn.LeakyReLU(0.2, True))\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.ReLU(True),\n            nn.ConvTranspose2d(32, 3, 4, 2, 1), nn.Tanh(),\n        )\n    \n    def forward(self, x):\n        z = self.fc_enc(self.encoder(x))\n        return self.decoder(self.fc_dec(z).view(-1, 512, 4, 4))\n\ndef train_model(seed, train_tensors, config, device):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    model = SimpleAE(config['latent_dim']).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n    criterion = nn.MSELoss()\n    loader = DataLoader(TensorDataset(train_tensors), batch_size=config['batch_size'], shuffle=True)\n    \n    best_loss, patience, best_state = float('inf'), 0, None\n    for epoch in range(config['num_epochs']):\n        model.train()\n        total_loss = sum(criterion(model(b[0]), b[0]).item() for b in loader)\n        avg_loss = total_loss / len(loader)\n        \n        # Proper training step\n        for (batch,) in loader:\n            optimizer.zero_grad(set_to_none=True)\n            loss = criterion(model(batch), batch)\n            loss.backward()\n            optimizer.step()\n        \n        if avg_loss < best_loss - 1e-5:\n            best_loss, patience = avg_loss, 0\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        else:\n            patience += 1\n        if patience >= config['patience']:\n            break\n    \n    if best_state:\n        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n    return model, best_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:19:12.288392Z","iopub.execute_input":"2026-01-07T06:19:12.289089Z","iopub.status.idle":"2026-01-07T06:19:12.299925Z","shell.execute_reply.started":"2026-01-07T06:19:12.289064Z","shell.execute_reply":"2026-01-07T06:19:12.299286Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"Training ensemble...\")\nmodels = []\nfor seed in CONFIG['seeds']:\n    print(f\"  Seed {seed}...\", end=\" \")\n    model, loss = train_model(seed, train_tensors, CONFIG, DEVICE)\n    models.append(model)\n    print(f\"loss={loss:.5f}\")\nprint(f\"Trained {len(models)} models\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:19:25.117277Z","iopub.execute_input":"2026-01-07T06:19:25.117557Z","iopub.status.idle":"2026-01-07T06:37:27.067207Z","shell.execute_reply.started":"2026-01-07T06:19:25.117534Z","shell.execute_reply":"2026-01-07T06:37:27.066273Z"}},"outputs":[{"name":"stdout","text":"Training ensemble...\n  Seed 42... loss=0.00212\n  Seed 123... loss=0.00219\n  Seed 456... loss=0.00223\n  Seed 789... loss=0.00219\nTrained 4 models\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"@torch.no_grad()\ndef get_max_scores(model, tensors, frame_info, batch_size=128):\n    model.eval()\n    scores = {}\n    for start in range(0, len(tensors), batch_size):\n        end = min(start + batch_size, len(tensors))\n        batch = tensors[start:end]\n        recon = model(batch)\n        max_err = torch.amax((batch - recon) ** 2, dim=(1, 2, 3))\n        for i, s in enumerate(max_err.cpu().numpy()):\n            vid, fnum = frame_info[start + i]\n            scores[f\"{vid}_{fnum}\"] = float(s)\n    return scores\n\nprint(\"Computing raw scores...\")\nall_raw_scores = []\nfor i, model in enumerate(models):\n    scores = get_max_scores(model, test_tensors, test_info)\n    all_raw_scores.append(scores)\n    print(f\"  Model {i+1} done\")\n\n# Average raw scores (before any normalization)\nraw_ensemble = {}\nfor fid in test_frame_ids:\n    raw_ensemble[fid] = np.mean([s[fid] for s in all_raw_scores])\nprint(f\"Raw ensemble computed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:38:10.365340Z","iopub.execute_input":"2026-01-07T06:38:10.366289Z","iopub.status.idle":"2026-01-07T06:38:25.996363Z","shell.execute_reply.started":"2026-01-07T06:38:10.366261Z","shell.execute_reply":"2026-01-07T06:38:25.995689Z"}},"outputs":[{"name":"stdout","text":"Computing raw scores...\n  Model 1 done\n  Model 2 done\n  Model 3 done\n  Model 4 done\nRaw ensemble computed\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def global_normalize(scores, clip_pct=99):\n    \"\"\"Standard global normalization (what we've been using).\"\"\"\n    vals = np.array(list(scores.values()))\n    keys = list(scores.keys())\n    clip_val = np.percentile(vals, clip_pct)\n    vals = np.clip(vals, 0, clip_val)\n    v_min, v_max = vals.min(), vals.max()\n    if v_max > v_min:\n        norm = (vals - v_min) / (v_max - v_min)\n    else:\n        norm = np.ones_like(vals) * 0.5\n    return {k: float(norm[i]) for i, k in enumerate(keys)}\n\ndef per_video_normalize(scores, test_video_fnums, clip_pct=99):\n    \"\"\"Normalize scores within each video independently.\"\"\"\n    normalized = {}\n    \n    for vid, fnums in test_video_fnums.items():\n        # Get scores for this video\n        vid_scores = [scores.get(f\"{vid}_{fn}\", 0) for fn in fnums]\n        vals = np.array(vid_scores)\n        \n        # Normalize within video\n        clip_val = np.percentile(vals, clip_pct)\n        vals = np.clip(vals, 0, clip_val)\n        v_min, v_max = vals.min(), vals.max()\n        \n        if v_max > v_min:\n            norm = (vals - v_min) / (v_max - v_min)\n        else:\n            norm = np.ones_like(vals) * 0.5\n        \n        for i, fn in enumerate(fnums):\n            normalized[f\"{vid}_{fn}\"] = float(norm[i])\n    \n    return normalized\n\ndef hybrid_normalize(scores, test_video_fnums, global_weight=0.5, clip_pct=99):\n    \"\"\"Combine global and per-video normalization.\"\"\"\n    global_norm = global_normalize(scores, clip_pct)\n    per_video_norm = per_video_normalize(scores, test_video_fnums, clip_pct)\n    \n    hybrid = {}\n    for fid in scores.keys():\n        hybrid[fid] = global_weight * global_norm[fid] + (1 - global_weight) * per_video_norm[fid]\n    \n    return global_normalize(hybrid, clip_pct=100)\n\nprint(\"Normalization functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:38:29.937689Z","iopub.execute_input":"2026-01-07T06:38:29.938249Z","iopub.status.idle":"2026-01-07T06:38:29.946881Z","shell.execute_reply.started":"2026-01-07T06:38:29.938224Z","shell.execute_reply":"2026-01-07T06:38:29.946226Z"}},"outputs":[{"name":"stdout","text":"Normalization functions defined\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def gaussian_smooth(scores, test_video_fnums, sigma):\n    if sigma == 0:\n        return scores.copy()\n    smoothed = {}\n    for vid, fnums in test_video_fnums.items():\n        vals = np.array([scores.get(f\"{vid}_{fn}\", 0) for fn in fnums])\n        if len(vals) > 1:\n            vals = gaussian_filter1d(vals, sigma=sigma)\n        for i, fn in enumerate(fnums):\n            smoothed[f\"{vid}_{fn}\"] = float(vals[i])\n    return smoothed\n\ndef median_smooth(scores, test_video_fnums, window):\n    if window <= 1:\n        return scores.copy()\n    smoothed = {}\n    for vid, fnums in test_video_fnums.items():\n        vals = np.array([scores.get(f\"{vid}_{fn}\", 0) for fn in fnums])\n        if len(vals) > window:\n            vals = median_filter(vals, size=window)\n        for i, fn in enumerate(fnums):\n            smoothed[f\"{vid}_{fn}\"] = float(vals[i])\n    return smoothed\n\ndef combined_smooth_gm(scores, test_video_fnums, gauss_sigma, median_window):\n    \"\"\"Gaussian first, then Median.\"\"\"\n    temp = gaussian_smooth(scores, test_video_fnums, gauss_sigma)\n    return median_smooth(temp, test_video_fnums, median_window)\n\ndef combined_smooth_mg(scores, test_video_fnums, median_window, gauss_sigma):\n    \"\"\"Median first, then Gaussian.\"\"\"\n    temp = median_smooth(scores, test_video_fnums, median_window)\n    return gaussian_smooth(temp, test_video_fnums, gauss_sigma)\n\nprint(\"Smoothing functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:38:46.246557Z","iopub.execute_input":"2026-01-07T06:38:46.247017Z","iopub.status.idle":"2026-01-07T06:38:46.254249Z","shell.execute_reply.started":"2026-01-07T06:38:46.246992Z","shell.execute_reply":"2026-01-07T06:38:46.253582Z"}},"outputs":[{"name":"stdout","text":"Smoothing functions defined\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"submissions = {}\n\n# 1. Per-video normalization + Gaussian σ=3 (our best smoothing)\nprint(\"1. Per-video norm + Gaussian σ=3\")\nper_vid_norm = per_video_normalize(raw_ensemble, test_video_fnums)\nper_vid_smooth = gaussian_smooth(per_vid_norm, test_video_fnums, sigma=3)\nsubmissions['pervid_gauss3'] = global_normalize(per_vid_smooth, clip_pct=100)\n\n# 2. Hybrid normalization (50% global, 50% per-video) + Gaussian σ=3\nprint(\"2. Hybrid norm + Gaussian σ=3\")\nhybrid_norm = hybrid_normalize(raw_ensemble, test_video_fnums, global_weight=0.5)\nhybrid_smooth = gaussian_smooth(hybrid_norm, test_video_fnums, sigma=3)\nsubmissions['hybrid_gauss3'] = global_normalize(hybrid_smooth, clip_pct=100)\n\n# 3. Combined smoothing: Gaussian σ=3 then Median w=5\nprint(\"3. Combined: Gaussian→Median\")\nglobal_norm = global_normalize(raw_ensemble)\ncombined_gm = combined_smooth_gm(global_norm, test_video_fnums, gauss_sigma=3, median_window=5)\nsubmissions['gauss3_median5'] = global_normalize(combined_gm, clip_pct=100)\n\n# 4. Combined smoothing: Median w=5 then Gaussian σ=3\nprint(\"4. Combined: Median→Gaussian\")\ncombined_mg = combined_smooth_mg(global_norm, test_video_fnums, median_window=5, gauss_sigma=3)\nsubmissions['median5_gauss3'] = global_normalize(combined_mg, clip_pct=100)\n\n# 5. Per-video norm + Combined smoothing (best of both ideas)\nprint(\"5. Per-video + Combined smoothing\")\nper_vid_combined = combined_smooth_gm(per_vid_norm, test_video_fnums, gauss_sigma=3, median_window=5)\nsubmissions['pervid_combined'] = global_normalize(per_vid_combined, clip_pct=100)\n\nprint(f\"\\nCreated {len(submissions)} submissions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:38:57.617126Z","iopub.execute_input":"2026-01-07T06:38:57.617790Z","iopub.status.idle":"2026-01-07T06:38:57.776678Z","shell.execute_reply.started":"2026-01-07T06:38:57.617766Z","shell.execute_reply":"2026-01-07T06:38:57.776075Z"}},"outputs":[{"name":"stdout","text":"1. Per-video norm + Gaussian σ=3\n2. Hybrid norm + Gaussian σ=3\n3. Combined: Gaussian→Median\n4. Combined: Median→Gaussian\n5. Per-video + Combined smoothing\n\nCreated 5 submissions\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def save_sub(scores, filename):\n    df = pd.DataFrame([{'Id': fid, 'Predicted': scores.get(fid, 0)} for fid in test_frame_ids])\n    df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\n    print(f\"Saved: {filename}\")\n\nprint(\"\\nSaving submissions...\")\nfor name, scores in submissions.items():\n    save_sub(scores, f'sub_{name}.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:39:08.555235Z","iopub.execute_input":"2026-01-07T06:39:08.555478Z","iopub.status.idle":"2026-01-07T06:39:08.712442Z","shell.execute_reply.started":"2026-01-07T06:39:08.555462Z","shell.execute_reply":"2026-01-07T06:39:08.711810Z"}},"outputs":[{"name":"stdout","text":"\nSaving submissions...\nSaved: sub_pervid_gauss3.csv\nSaved: sub_hybrid_gauss3.csv\nSaved: sub_gauss3_median5.csv\nSaved: sub_median5_gauss3.csv\nSaved: sub_pervid_combined.csv\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Cleanup\ndel train_tensors, test_tensors, models\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:55:10.713187Z","iopub.execute_input":"2026-01-07T06:55:10.713864Z","iopub.status.idle":"2026-01-07T06:55:10.892518Z","shell.execute_reply.started":"2026-01-07T06:55:10.713838Z","shell.execute_reply":"2026-01-07T06:55:10.891769Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}