{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":126766,"databundleVersionId":15067517,"sourceType":"competition"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {DEVICE}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:40:51.695084Z","iopub.execute_input":"2026-01-05T04:40:51.695356Z","iopub.status.idle":"2026-01-05T04:41:01.080105Z","shell.execute_reply.started":"2026-01-05T04:40:51.695324Z","shell.execute_reply":"2026-01-05T04:41:01.079367Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Paths\nBASE_PATH = \"/kaggle/input/pixel-play-26\"\nDATA_ROOT = os.path.join(BASE_PATH, os.listdir(BASE_PATH)[0])\nAVENUE_PATH = os.path.join(DATA_ROOT, \"Avenue_Corrupted\", \"Dataset\")\nTRAIN_VIDEOS = os.path.join(AVENUE_PATH, \"training_videos\")\nTEST_VIDEOS = os.path.join(AVENUE_PATH, \"testing_videos\")\nOUTPUT_DIR = \"/kaggle/working\"\n\n# Config\nCONFIG = {\n    'image_size': (128, 128),\n    'latent_dim': 128,\n    'batch_size': 64,\n    'num_epochs': 25,\n    'learning_rate': 2e-4,\n    'patience': 5,\n    'seeds': [42, 123, 456],  # Multiple seeds for ensemble\n}\n\nprint(\"Config ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:41:01.081869Z","iopub.execute_input":"2026-01-05T04:41:01.082218Z","iopub.status.idle":"2026-01-05T04:41:01.089939Z","shell.execute_reply.started":"2026-01-05T04:41:01.082195Z","shell.execute_reply":"2026-01-05T04:41:01.089352Z"}},"outputs":[{"name":"stdout","text":"Config ready\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def discover_frames(video_dir):\n    frames = defaultdict(list)\n    if not os.path.exists(video_dir):\n        return frames\n    for vf in sorted(glob.glob(os.path.join(video_dir, '*'))):\n        if not os.path.isdir(vf):\n            continue\n        try:\n            vid = int(os.path.basename(vf))\n        except:\n            continue\n        for ff in sorted(glob.glob(os.path.join(vf, '*.jpg'))):\n            fname = os.path.splitext(os.path.basename(ff))[0]\n            if fname.startswith('frame_'):\n                fname = fname.replace('frame_', '')\n            try:\n                fnum = int(fname)\n                frames[vid].append((fnum, ff))\n            except:\n                continue\n        frames[vid].sort(key=lambda x: x[0])\n    return dict(frames)\n\ntrain_frames = discover_frames(TRAIN_VIDEOS)\ntest_frames = discover_frames(TEST_VIDEOS)\nprint(f\"Train: {sum(len(v) for v in train_frames.values())} frames\")\nprint(f\"Test: {sum(len(v) for v in test_frames.values())} frames\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:41:01.090911Z","iopub.execute_input":"2026-01-05T04:41:01.091225Z","iopub.status.idle":"2026-01-05T04:41:01.805080Z","shell.execute_reply.started":"2026-01-05T04:41:01.091198Z","shell.execute_reply":"2026-01-05T04:41:01.804320Z"}},"outputs":[{"name":"stdout","text":"Train: 9204 frames\nTest: 11706 frames\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Build test frame IDs\ntest_frame_ids = []\ntest_frame_info = []\nfor vid in sorted(test_frames.keys()):\n    for fnum, _ in test_frames[vid]:\n        test_frame_ids.append(f\"{vid}_{fnum}\")\n        test_frame_info.append((vid, fnum))\nprint(f\"Test IDs: {len(test_frame_ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:41:01.805930Z","iopub.execute_input":"2026-01-05T04:41:01.806154Z","iopub.status.idle":"2026-01-05T04:41:01.816999Z","shell.execute_reply.started":"2026-01-05T04:41:01.806122Z","shell.execute_reply":"2026-01-05T04:41:01.816325Z"}},"outputs":[{"name":"stdout","text":"Test IDs: 11706\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def load_frames_to_gpu(frames_dict, image_size, device):\n    total = sum(len(v) for v in frames_dict.values())\n    H, W = image_size\n    all_frames = torch.zeros(total, 3, H, W, dtype=torch.float32, device=device)\n    frame_info = []\n    idx = 0\n    for vid in sorted(frames_dict.keys()):\n        for fnum, path in frames_dict[vid]:\n            img = Image.open(path).convert('RGB').resize((W, H), Image.BILINEAR)\n            arr = np.array(img, dtype=np.float32) / 127.5 - 1.0\n            all_frames[idx] = torch.from_numpy(arr).permute(2, 0, 1)\n            frame_info.append((vid, fnum))\n            idx += 1\n    return all_frames, frame_info\n\nprint(\"Loading data to GPU...\")\ntrain_tensors, train_info = load_frames_to_gpu(train_frames, CONFIG['image_size'], DEVICE)\ntest_tensors, test_info = load_frames_to_gpu(test_frames, CONFIG['image_size'], DEVICE)\nprint(f\"Loaded. GPU: {torch.cuda.memory_allocated()/1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:41:01.820017Z","iopub.execute_input":"2026-01-05T04:41:01.820330Z","iopub.status.idle":"2026-01-05T04:45:27.676536Z","shell.execute_reply.started":"2026-01-05T04:41:01.820308Z","shell.execute_reply":"2026-01-05T04:45:27.675702Z"}},"outputs":[{"name":"stdout","text":"Loading data to GPU...\nLoaded. GPU: 4.11 GB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class GPUDataset(Dataset):\n    def __init__(self, tensors):\n        self.tensors = tensors\n    def __len__(self):\n        return len(self.tensors)\n    def __getitem__(self, idx):\n        return self.tensors[idx]\n\ntrain_dataset = GPUDataset(train_tensors)\ntrain_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\nprint(f\"Train loader: {len(train_loader)} batches\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:45:27.677559Z","iopub.execute_input":"2026-01-05T04:45:27.677886Z","iopub.status.idle":"2026-01-05T04:45:27.683340Z","shell.execute_reply.started":"2026-01-05T04:45:27.677854Z","shell.execute_reply":"2026-01-05T04:45:27.682470Z"}},"outputs":[{"name":"stdout","text":"Train loader: 144 batches\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"class SimpleAutoencoder(nn.Module):\n    def __init__(self, latent_dim=128):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(32, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, True),\n            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, True),\n        )\n        self.fc_enc = nn.Sequential(nn.Flatten(), nn.Linear(512*4*4, latent_dim))\n        self.fc_dec = nn.Sequential(nn.Linear(latent_dim, 512*4*4), nn.LeakyReLU(0.2, True))\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.ReLU(True),\n            nn.ConvTranspose2d(32, 3, 4, 2, 1), nn.Tanh(),\n        )\n    \n    def forward(self, x):\n        z = self.fc_enc(self.encoder(x))\n        return self.decoder(self.fc_dec(z).view(-1, 512, 4, 4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:45:27.684179Z","iopub.execute_input":"2026-01-05T04:45:27.684508Z","iopub.status.idle":"2026-01-05T04:45:27.703066Z","shell.execute_reply.started":"2026-01-05T04:45:27.684488Z","shell.execute_reply":"2026-01-05T04:45:27.702541Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train_model(seed, train_loader, config, device):\n    \"\"\"Train a single model with given seed.\"\"\"\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    \n    model = SimpleAutoencoder(config['latent_dim']).to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n    \n    best_loss = float('inf')\n    patience_counter = 0\n    \n    for epoch in range(config['num_epochs']):\n        model.train()\n        epoch_loss = 0\n        \n        for batch in train_loader:\n            optimizer.zero_grad(set_to_none=True)\n            recon = model(batch)\n            loss = criterion(recon, batch)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        \n        avg_loss = epoch_loss / len(train_loader)\n        \n        if avg_loss < best_loss - 1e-4:\n            best_loss = avg_loss\n            patience_counter = 0\n            best_state = model.state_dict().copy()\n        else:\n            patience_counter += 1\n        \n        if (epoch + 1) % 5 == 0:\n            print(f\"  Epoch {epoch+1}: loss={avg_loss:.5f}\")\n        \n        if patience_counter >= config['patience']:\n            print(f\"  Early stop at epoch {epoch+1}\")\n            break\n    \n    model.load_state_dict(best_state)\n    return model, best_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:45:27.703936Z","iopub.execute_input":"2026-01-05T04:45:27.704400Z","iopub.status.idle":"2026-01-05T04:45:27.723337Z","shell.execute_reply.started":"2026-01-05T04:45:27.704379Z","shell.execute_reply":"2026-01-05T04:45:27.722769Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Train ensemble of models\nprint(\"=\" * 60)\nprint(\"TRAINING ENSEMBLE\")\nprint(\"=\" * 60)\n\nmodels = []\nfor i, seed in enumerate(CONFIG['seeds']):\n    print(f\"\\nModel {i+1}/{len(CONFIG['seeds'])} (seed={seed})\")\n    model, loss = train_model(seed, train_loader, CONFIG, DEVICE)\n    models.append(model)\n    print(f\"  Best loss: {loss:.5f}\")\n\nprint(f\"\\nTrained {len(models)} models\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:45:27.724079Z","iopub.execute_input":"2026-01-05T04:45:27.724345Z","iopub.status.idle":"2026-01-05T04:56:26.579251Z","shell.execute_reply.started":"2026-01-05T04:45:27.724319Z","shell.execute_reply":"2026-01-05T04:56:26.578479Z"}},"outputs":[{"name":"stdout","text":"============================================================\nTRAINING ENSEMBLE\n============================================================\n\nModel 1/3 (seed=42)\n  Epoch 5: loss=0.00623\n  Epoch 10: loss=0.00381\n  Epoch 15: loss=0.00289\n  Epoch 20: loss=0.00242\n  Epoch 25: loss=0.00213\n  Best loss: 0.00217\n\nModel 2/3 (seed=123)\n  Epoch 5: loss=0.00646\n  Epoch 10: loss=0.00393\n  Epoch 15: loss=0.00297\n  Epoch 20: loss=0.00246\n  Epoch 25: loss=0.00214\n  Best loss: 0.00214\n\nModel 3/3 (seed=456)\n  Epoch 5: loss=0.00635\n  Epoch 10: loss=0.00391\n  Epoch 15: loss=0.00301\n  Epoch 20: loss=0.00250\n  Epoch 25: loss=0.00222\n  Best loss: 0.00231\n\nTrained 3 models\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"@torch.no_grad()\ndef compute_scores(model, tensors, frame_info, batch_size=128):\n    \"\"\"Compute mean and max reconstruction error.\"\"\"\n    model.eval()\n    scores_mean = {}\n    scores_max = {}\n    \n    for start in range(0, len(tensors), batch_size):\n        end = min(start + batch_size, len(tensors))\n        batch = tensors[start:end]\n        recon = model(batch)\n        \n        pixel_err = (batch - recon) ** 2\n        mean_err = torch.mean(pixel_err, dim=(1,2,3))\n        max_err = torch.amax(pixel_err, dim=(1,2,3))\n        \n        for i in range(len(batch)):\n            vid, fnum = frame_info[start + i]\n            fid = f\"{vid}_{fnum}\"\n            scores_mean[fid] = float(mean_err[i].cpu())\n            scores_max[fid] = float(max_err[i].cpu())\n    \n    return scores_mean, scores_max","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:26.580286Z","iopub.execute_input":"2026-01-05T04:56:26.580651Z","iopub.status.idle":"2026-01-05T04:56:26.586512Z","shell.execute_reply.started":"2026-01-05T04:56:26.580627Z","shell.execute_reply":"2026-01-05T04:56:26.585842Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Compute scores from all models\nprint(\"Computing scores from all models...\")\n\nall_mean_scores = []\nall_max_scores = []\n\nfor i, model in enumerate(models):\n    print(f\"Model {i+1}...\")\n    mean_s, max_s = compute_scores(model, test_tensors, test_info)\n    all_mean_scores.append(mean_s)\n    all_max_scores.append(max_s)\n\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:26.587363Z","iopub.execute_input":"2026-01-05T04:56:26.587631Z","iopub.status.idle":"2026-01-05T04:56:40.233442Z","shell.execute_reply.started":"2026-01-05T04:56:26.587600Z","shell.execute_reply":"2026-01-05T04:56:40.232868Z"}},"outputs":[{"name":"stdout","text":"Computing scores from all models...\nModel 1...\nModel 2...\nModel 3...\nDone!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def normalize(scores, clip_pct=99):\n    vals = np.array(list(scores.values()))\n    keys = list(scores.keys())\n    clip_val = np.percentile(vals, clip_pct)\n    vals = np.clip(vals, 0, clip_val)\n    v_min, v_max = vals.min(), vals.max()\n    if v_max - v_min > 1e-8:\n        norm = (vals - v_min) / (v_max - v_min)\n    else:\n        norm = np.ones_like(vals) * 0.5\n    return {k: float(norm[i]) for i, k in enumerate(keys)}\n\ndef ensemble_scores(score_list):\n    \"\"\"Average scores from multiple models.\"\"\"\n    keys = list(score_list[0].keys())\n    ensembled = {}\n    for k in keys:\n        ensembled[k] = np.mean([s[k] for s in score_list])\n    return ensembled\n\n# Ensemble the scores\nprint(\"Ensembling scores from all models...\")\nmean_ensemble = ensemble_scores(all_mean_scores)\nmax_ensemble = ensemble_scores(all_max_scores)\n\n# Normalize\nmean_norm = normalize(mean_ensemble)\nmax_norm = normalize(max_ensemble)\n\nprint(f\"Ensembled {len(models)} models\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:40.234388Z","iopub.execute_input":"2026-01-05T04:56:40.234627Z","iopub.status.idle":"2026-01-05T04:56:40.435474Z","shell.execute_reply.started":"2026-01-05T04:56:40.234604Z","shell.execute_reply":"2026-01-05T04:56:40.434710Z"}},"outputs":[{"name":"stdout","text":"Ensembling scores from all models...\nEnsembled 3 models\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Try different mean/max ratios\nRATIOS = {\n    'mean100': (1.0, 0.0),   # Pure mean\n    'mean80': (0.8, 0.2),\n    'mean70': (0.7, 0.3),\n    'mean60': (0.6, 0.4),    # Previous best\n    'mean50': (0.5, 0.5),\n    'mean40': (0.4, 0.6),\n    'max100': (0.0, 1.0),    # Pure max\n}\n\ndef create_fused(mean_scores, max_scores, mean_weight, max_weight):\n    fused = {}\n    for fid in mean_scores.keys():\n        fused[fid] = mean_weight * mean_scores[fid] + max_weight * max_scores[fid]\n    return normalize(fused, clip_pct=100)\n\nfused_scores = {}\nfor name, (mw, xw) in RATIOS.items():\n    fused_scores[name] = create_fused(mean_norm, max_norm, mw, xw)\n    print(f\"Created: {name} (mean={mw}, max={xw})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:40.436280Z","iopub.execute_input":"2026-01-05T04:56:40.436495Z","iopub.status.idle":"2026-01-05T04:56:40.489328Z","shell.execute_reply.started":"2026-01-05T04:56:40.436475Z","shell.execute_reply":"2026-01-05T04:56:40.488619Z"}},"outputs":[{"name":"stdout","text":"Created: mean100 (mean=1.0, max=0.0)\nCreated: mean80 (mean=0.8, max=0.2)\nCreated: mean70 (mean=0.7, max=0.3)\nCreated: mean60 (mean=0.6, max=0.4)\nCreated: mean50 (mean=0.5, max=0.5)\nCreated: mean40 (mean=0.4, max=0.6)\nCreated: max100 (mean=0.0, max=1.0)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def save_sub(scores, filename):\n    df = pd.DataFrame([{'Id': fid, 'Predicted': scores.get(fid, 0)} for fid in test_frame_ids])\n    df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\n    print(f\"Saved: {filename}\")\n    return df\n\n# Save all ratio variations\nfor name, scores in fused_scores.items():\n    save_sub(scores, f'sub_ensemble_{name}.csv')\n\nprint(f\"\\nGenerated {len(fused_scores)} submissions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:40.491768Z","iopub.execute_input":"2026-01-05T04:56:40.492032Z","iopub.status.idle":"2026-01-05T04:56:40.886826Z","shell.execute_reply.started":"2026-01-05T04:56:40.492012Z","shell.execute_reply":"2026-01-05T04:56:40.886206Z"}},"outputs":[{"name":"stdout","text":"Saved: sub_ensemble_mean100.csv\nSaved: sub_ensemble_mean80.csv\nSaved: sub_ensemble_mean70.csv\nSaved: sub_ensemble_mean60.csv\nSaved: sub_ensemble_mean50.csv\nSaved: sub_ensemble_mean40.csv\nSaved: sub_ensemble_max100.csv\n\nGenerated 7 submissions\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Sometimes a single model beats ensemble - save best individual too\nprint(\"\\nSaving individual model scores (60/40 ratio)...\")\n\nfor i, (mean_s, max_s) in enumerate(zip(all_mean_scores, all_max_scores)):\n    mean_n = normalize(mean_s)\n    max_n = normalize(max_s)\n    fused = create_fused(mean_n, max_n, 0.6, 0.4)\n    save_sub(fused, f'sub_model{i+1}_mean60.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:40.887802Z","iopub.execute_input":"2026-01-05T04:56:40.888203Z","iopub.status.idle":"2026-01-05T04:56:41.019613Z","shell.execute_reply.started":"2026-01-05T04:56:40.888172Z","shell.execute_reply":"2026-01-05T04:56:41.018984Z"}},"outputs":[{"name":"stdout","text":"\nSaving individual model scores (60/40 ratio)...\nSaved: sub_model1_mean60.csv\nSaved: sub_model2_mean60.csv\nSaved: sub_model3_mean60.csv\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Cleanup\ndel train_tensors, test_tensors, models\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T04:56:41.020416Z","iopub.execute_input":"2026-01-05T04:56:41.020648Z","iopub.status.idle":"2026-01-05T04:56:41.171592Z","shell.execute_reply.started":"2026-01-05T04:56:41.020631Z","shell.execute_reply":"2026-01-05T04:56:41.170991Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}